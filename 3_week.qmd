---
title: "Corrections"
output: html_document
bibliography: references.bib
---

::: column-body
We now understand the role of EMW its interaction, transmission, reflection, reception which that leads to data storage in bits (sensor (one or multiple) on a satellite\>sensor (active/passive)\>target area\> sensor\> recorded in pixel forming band\> multiple band with various information\> final digital image. (Refer Week 1)

We already know of types of sensors and what they do (Week 1), this week we learnt on how they do it and the challenges of producing the desired output.

The challenge here is the corrections that need to be done to the input received.
:::

### Principle Imaging Sensor Systems

::: column-body
Indicated below are primary ways of image recording.

![](images/Image%20recording.png){fig-align="center" width="357"}

1.  Analogue

![Analogue Camera. SOURCE: [freepik.com](https://www.freepik.com/premium-photo/film-camera-with-film-reel-white-backgroundx9_32140064.htm)](images/film-camera-with-film-reel-white-backgroundx9_711966-59.png){width="288"}

2.  Digital

![TerraLuma pushbroom system: Image (top left) and drawing of the sensor payload (top right) and device interaction flow chart (bottom; CAD design and flow chart: Richard Ballard, TerraLuma group). Source: [mdpi](https://www.mdpi.com/2072-4292/10/7/1091)](images/remotesensing-10-01091-g003.png){fig-align="center" width="331"}

![Imaging sensor Systems. SOURCE: [geo-informatie](http://www.geo-informatie.nl/courses/grs20306/lectures/07digitalremotesensingpartb/07digitalremotesensingpartb12.htm)](images/07digitalremotesensingpartb12.png){fig-align="center"}
:::

### Scanning modes

::: column-body
In this section we see how the Digital recording is carried out- by scanning!!, indicated below are the various scanning modes.

![Types of Scanning Modes](images/Scanningtypes.png){fig-align="center" width="450"}

![Cross-Track and Along Track Scanner. SOURCE: [onestopgis](https://www.onestopgis.com/Aerial-Photography/Digital-Imaging/Sensors/1-Remote-Sensing-Systems.html)](images/Track-scanning-systems-for-acquiring-remote-sensing.png){fig-align="center"}

![Circular and side scanning systems. SOURCE: [onestopgis](https://www.onestopgis.com/Aerial-Photography/Digital-Imaging/Sensors/1-Remote-Sensing-Systems.html)](images/Factors-affecting-signal-strength-of-an-image.png){fig-align="center"}
:::

::: column-body
1.  Cross- Track Scanning System - Passive system
2.  Along- Track Scanning System - Passive system
3.  Circular Scanning System - Passive system
4.  Side Scanning System
:::

::: column-body
##### 1. Cross- Track Scanning System - Passive system

-   Widely used
-   faceted mirror- horizontal axis of rotation-aligned parallel with flight direction
-   sweeping= parallel scan lines oriented normal (perpendicular) to filght direction.
-   High Scanner speed is
:::

::: column-body
##### 2. Along- Track Scanning System - Passive system

-   Along track scanning/ push-broom scanners= movement of the ground resolution cells
-   has individual detector- insead of mirrior-
    -   to increase dwell time for each ground resolution
    -   hence elemination of scanning mirrior
    -   introduction of individual detector for each ground resolution cell (across the swath)
    -   placement of detectors- linear array (focal plane of the image)
-   orientation of long axis of linear array- Normal to light path
-   IFOV of detector- sweeps terrain prallel with the flight track
-   Increased dwell time
    -   ditectors: smaller IFOC (finer SPATIAL resolution) and narrow spectral bandwidth (higher SPECTRAL resolution)
:::

::: column-body
##### 3. Circular Scanning System - Passive system

-   mounting of scan monitor and mirror= vertical axis of rotation
-   path of sweeping- circular
-   only forward portion of sweep is recorded
-   processing and display systems designed for linear scan data
-   circular scan data
-   extensively reformatted (prior processing)
-   short dwell time (compared to cross- track scanners)
-   Application:
    -   reconnaissance purpose (heli and low flying aircraft)
:::

::: column-body
##### 4. Side Scanning System- Active System

-   Active system
-   Eg: sonar (SOund NAvigation and Ranging)
-   Application:
    -   Map seafloors
    -   Habitat of marine animals
    -   Detecting imaging objects in sea floors
    -   Transducer array sent and recieved
    -   Mounted on ship's hull
-   Benefits: less expensive
-   Issues: cannot measure: Bathymetry (depth)
-   solution: use it in tandem single-bean and multibean sonar
:::

![remote sensing system used for multi-spectral and Hyper- Spectral Data collection. SOURCE: [onestopgis](https://www.onestopgis.com/Aerial-Photography/Digital-Imaging/Sensors/1-Remote-Sensing-Systems.html)](images/Multi-spectral-and-Hyper-spectral-Data-Collection.png)

#### Factors affecting Signal Strength

::: column-body
The scanning is done to receive back a signal to create a pixel\>band with information. But! the signal we receive back can have varied strength due to various factors that affect it, indicated below are the same:

-   Energy Flux
-   altitude
-   Spectral Bandwidth of the detector
-   instantaneous field of view
-   Dwell time
:::

::: column-body
### Scan Lines

"A remote-sensing tool with a line of many fixed sensors that record reflected radiation from the terrain along a satellite's direction of movement, creating scan-line strips that are contiguous or that overlap slightly, thereby producing an image" [esri](https://support.esri.com/en-us/gis-dictionary/along-track-scanner#:~:text=%5Bremote%20sensing%5D%20A%20remote%2D,slightly%2C%20thereby%20producing%20an%20image.)
:::

![The chain of satellite data acquisition. The scanning device records data, pixel by pixel, along a scan line. Assembling the scan lines gives an image. The radiation is recorded in grey levels. SOURCE: @adamo2020](images/The-chain-of-satellite-data-acquisition-The-scanning-device-records-data-pixel-by_W640.jpg){fig-align="center"}

## View: Perspective and Planimetry

::: column-body
Now we understand how the scanning is performed by a Sensor (above sections), we further need to understand about perspective. How the object can be viewed so as to better understand corrections.
:::

![Orthographic and View. *SOURCE: [mashyo](https://mashyo.com/3d-views/)*](images/3d-projections.png.webp){fig-align="center" width="392"}

+-----------------------+------------------------------------------------+---------------------------------------------------------------------------------------------------+
|                       | Perspective View                               | Planimetric View                                                                                  |
+:======================+:===============================================+:==================================================================================================+
| lights rays reflected | pass through one single point at the center    | looks as through every position on the ground is being viewed from directly above                 |
+-----------------------+------------------------------------------------+---------------------------------------------------------------------------------------------------+
| Scale                 | Varies                                         | everywhere consistent (if we overlook variation in small- scale maps (map projections)            |
+-----------------------+------------------------------------------------+---------------------------------------------------------------------------------------------------+
| view                  | objects far away = smaller                     | all objects appear to be of the same scale.                                                       |
|                       |                                                |                                                                                                   |
|                       | objects close= bigger                          |                                                                                                   |
+-----------------------+------------------------------------------------+---------------------------------------------------------------------------------------------------+
| perception            | more perspective of depth                      | comparatively no (as easier to compare between two points, as there is no perception of distance) |
+-----------------------+------------------------------------------------+---------------------------------------------------------------------------------------------------+
|                       | more realistic looking due to depth perception | accurate measure, details are clear                                                               |
+-----------------------+------------------------------------------------+---------------------------------------------------------------------------------------------------+
| Example               | photo-realistic renderings or animations       | Topographic maps, Orthoimages, technical drawings and architectural plans etc.                    |
+-----------------------+------------------------------------------------+---------------------------------------------------------------------------------------------------+

![Orthographic and Perspective View. *SOURCE: [wikipedia](https://en.wikipedia.org/wiki/Orthophoto#/media/File:OrthoPerspective.svg)*](images/1024px-OrthoPerspective.svg.png){fig-align="center" width="491"}

::: column-body
## Image correction!

-   Raw remotely sensed data- ISSUES
    -   Geometric and radiometric flaws -- why?
    -   Curved shape of the Earth
    -   Imperfectly transparent atmosphere
    -   Daily and seasonal variations (receiving solar radiation)
    -   Imperfections in scanning instruments
-   why do we need image correction??
    -   to remove distortion= individual picture elements are in their proper plainmetric (x,y).
:::

![Distortion and Correction](images/distortion.png){fig-align="center"}

::: column-body
### Radiometric Correction

-   Precisely estimate the reflectively of an environment
-   Meaning: improve the brightness value/ reduce inconsistencies in image brightness (not spatial or locational aspects)
-   Errors= **Noise**
-   How?
    -   compensating for the distortions (antenna system , positioning errors etc.)
    -   eg: [ncl.ac.uk](https://www.ncl.ac.uk/tcmweb/bilko/module7/lesson3.pdf); [l3harrisgeospatial](https://www.l3harrisgeospatial.com/docs/radiometriccalibration.html)
-   Correction procedures [storymaps](https://storymaps.arcgis.com/stories/9fe04283db7048adb93c642c3d07dfc4)
    -   Radiative Transfer Code Model: Clear atmospheric conditions, creating scattering models. requires data retrieved from ground. accuracy= High
    -   Image-based: Information source= image, accuracy= low
    -   Regression: analyses each band, estimation of brightness in each image
:::

::: column-body
### Geometric Correction

PROCESS:

-   Correcting geometric distortion
-   Assigning properties of a map to an image

Source:

-   Relief displacement
    -   less factor: satellite remote sensing (due to altitude)
    -   high factor: aerial imagin
-   Earth curvature
    -   curvature
    -   eastward spinning
-   ORBIT:
    -   ORBIT of earth:West to East
    -   ORBIT of satellite: pole to pole (IKONOS, Landsat, and the NOAA)
    -   Cylindrical projection: S shape waves
-   Each scan row begins at a position slightly west of the row that preceded it
-   First pixel in each row appears to be aligned with the other initial pixels

Geometric correction solution modelling 2 solution: - Jensen page 244 describes - RMSE
:::

![Geometric Correction](images/geometric.png){fig-align="center" width="778"}

::: column-body
### Atmospheric Correction

-   Need:
    -   To remove the scattering and absorption effects from the atmosphere
    -   Why?- to obtain surface reflectance characteristics

1.  Atmospheric scattering (as we saw in week 1)
2.  Topographic attenuation (up next)
3.  Unnecessary
4.  Necessary
:::

::: column-body
#### 1. Atmospheric scattering

Types:

-   Dark object subtraction
-   Psuedo-invariant Features
-   Absolute(definitive)
-   4th - Empirical Line Correction (3)
:::

::: column-body
#### 2. Topographic Correction

-   Orthorectification Correction (6)
-   Radiometric Calibration
-   Landsat ARD- Surface reflectance
-   Joining data sets
-   Image Enhancement
:::

::: column-body
#### 3. Unnecessary

-   Ortho
:::

::: column-body
#### 4. Necessary

-   Orthorect
:::

### Resampling

::: column-body
-   Extraction of a brightness value from an x, y location
:::

![Re-sampling types](images/resampling_.png){fig-align="center"}

+------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+
| Nearest Neighbour                                                      | Bilinear                                                                                                                                                           | Cubic                                      |
+:=======================================================================+:===================================================================================================================================================================+:===========================================+
| -   Brightness value Assigning:                                        | -   Assigning:                                                                                                                                                     | similar to Bilinear                        |
|     -   OUTPUT (x',y') \<= closed to the specified (x', y') coordinate |                                                                                                                                                                    |                                            |
|     -   OR                                                             |     -   OUTPUT pixel values \<= two orthogonal directions in the input image                                                                                       | -   weighted value assignment:             |
|     -   Assigned value OUTPUT pixel= NEAREST input pixel               |     -   OR                                                                                                                                                         |                                            |
| -   Computation: Pythagorean theorem                                   |     -   Fits (plane of four-pixel value) NEAREST to the desired position in the input image =\> computes =\> new brightness value (based on the weighted distance) |     -   computing 16 input pixel values    |
| -   Advantage:                                                         |                                                                                                                                                                    |     -   surrounding desired x',y' location |
|     -   DOES NOT alter image pixel value                               |                                                                                                                                                                    |     -   +\> estimate the output pixel      |
+------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------+

![](images/image-2019968424.png)

![Nearest-Neighbour. Source: [esa](https://lps16.esa.int/posterfiles/paper1213/%5bRD3%5d_Philpot_615_04_GeomCorrect_rev01.pdf)](images/image-1493748426.png){alt="Nearest-Neighbour. Source: esa" fig-align="center"}

![Bilinear Interpolation. Source: [esa](https://lps16.esa.int/posterfiles/paper1213/%5bRD3%5d_Philpot_615_04_GeomCorrect_rev01.pdf)](images/image-1975374788.png){alt="Bilinear Interpolation. Source: esa"}

## Application

::: column-body
@yan2012Radiometric

-   LiDAR system (maximize the benefit of LiDAR data). How? requires geometric calibration (GC) and radiometric correction (RC) ![Experimental workflow for the geometric calibration and radiometric correction of LiDAR data and land cover classification](images/image-746277220.png){alt="Experimental workflow for the geometric calibration and radiometric correction of LiDAR data and land cover classification" width="317"}

-   Study area: British Columbia Institute of Technology (BCIT) , Burnaby, British Columbia, Canada

-   Feasibility of the proposed GC and RC methods: LiDAR dataset

-   Date: July 17, 2009 at local time 14:55

-   Temp: 29.8 °C

-   Vertical visibility = 48.3 km

-   The pressure = 101.81 kPa

-   Source: National Climate Data and Information Archive from Environment Canada

-   Sensor: Leica ALS50

    -   Average flying height= 600 m
    -   Point density= 4--5 points per meter square

-   Why choose the study area?- variety in land cover

-   Subset:

    -   Subset of a single LiDAR strip \>\> clipped
    -   Dimension = 500 m × 400 m (experimental testing)
    -   Direction of the flight survey = west-\> east
    -   points= 1 Mn
    -   calibration: geometrically calibrated using the quasi
    -   rigorous method

-   Four Datasets: used for land cover classification and comparative analysis

    -   Original intensity data
    -   GC intensity data
    -   RC intensity data
    -   GC and RC intensity data

-   Intensity data image classification= Gaussian maximum likelihood classification (MLC) technique

-   calculation= kappa statistics + overall accuracy

-   three classification scenarios

-   4 data sets

    ![](images/image-814032790.png){width="381"}

![](images/image-1552736374.png){width="356"}

-   Requirement of method:
    -   Time
    -   Tagged point cloud
    -   Trajectory position data
-   Results and Discussion
-   Radiometric correction (when system raw measurements are not available)
-   Geometric system calibration= improve scan mirrors angles and ranges.
-   Considerations of correction:
    -   System parameters
    -   Topographic effect
    -   Atmospheric attenuation
-   Post training:
    -   The separabilities
        -   Training areas (land cover classes intensity values)= higher ( compared to the original intensity data)

        -   result= expected accuracy improvement (land cover classification)

            ![](images/image-1855403524.png){width="366"}
-   Classification results \>\> assessed and compared \>\> different scenarios of 3- to 5-feature classes
    -   Original intensity data =31% to 61% (classification accuracy range)
    -   GC intensity data = 0.1% to 1.6% (classification accuracy improvement in intensity)
    -   RC intensity data= 8.0% to 11.6% (classification accuracy improvement in intensity)
    -   GC and RC intensity data= 43% to 70% (classification accuracy range) ; 9.4% to 12.8% (classification accuracy improvement in intensity)
    -   GC and RC should be implemented for LiDAR (improves accuracy)
:::

## Reflection

::: column-body
-   Geometric and radiometric corrections are most common in remote sensing.
-   Occurs in the data acquisition process, resulting in reducing the quality of the data (remotely sensed)
-   It is essential to correct radiometric distortions to obtain a real reflectance
-   Calibrated image result is different from un-calibrated= correction is required
-   Radiometric comparability importance=
    -   Surface features(over a time period)
    -   Comparison of data (eg: lab to field)
-   Radiometric= geo-referencing an image \>\> comparison of one image pixel to another which is geo-spatially matching (can be from a different sensor, but compatible resolution)
-   If different accusation dates of 2 image= change observed in calculating the radiometric difference.
-   Sun spot= "The solar radiation will be reflected diffusely onto the ground surface, which results in lighter areas in an image" [sar.kangwon](http://sar.kangwon.ac.kr/etc/rs_note/rsnote/cp9/cp9-1.htm#:~:text=In%20the%20case%20of%20electro,be%20used%20for%20radiometric%20correction.&text=The%20solar%20radiation%20will%20be,is%20called%20a%20sun%20spot.)
-   @paolini2006; @small2007
:::

![The flow of geometric correction. Source: [dspmuranchi](http://www.dspmuranchi.ac.in/pdf/Blog/Pre-Processing%20&%20Correction%20of%20Digital%20Image.pdf)](images/image-850521088.png){fig-align="center" width="493"}
